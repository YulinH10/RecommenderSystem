# LLM在推荐系统中的3大落地方向
> https://mp.weixin.qq.com/s/BlHpFuAPRUheMJf-Vz5jtg
> https://zhuanlan.zhihu.com/p/1943623760025482844

一定要清楚信息增量在哪、模型结构的优化点在哪

## 一、大模型改变了“知识学习”的方式

大语言模型的出现，特别是多模态大模型的出现，毫无疑问改变了AI学习理解知识的方式。

传统的深度学习推荐模型对知识的学习其实是封闭式的，它依赖人工的内容型特征的筛选和构造来学习知识，同时它的知识范围一般限于公司的内部推荐数据。而大模型的知识学习是开放式的，一个大模型就可以融会贯通开放世界中能获取到的几乎所有知识，这是之前没有技术能够达到的。


这就带来了推荐系统在“知识输入”上的革命。大模型融合的开放世界知识将带给推荐系统丰富的增量信息，多模态大模型对于图片、视频的理解能力带来了更为丰富的多模态知识输入。这对于推荐系统的特征工程、冷启动、内容理解的意义重大。

> 对推荐系统知识获取方式的改造

大模型的知识与推荐系统的知识是“完美互补”的关系。大模型的知识是开放的、多模态的，它从开放世界学习到的外部知识将给推荐系统带来大量的“新鲜血液”；但与此同时，大模型缺乏推荐系统内部的用户行为信息，这也就意味着大模型无法完全替代推荐系统的知识体系。最合理的方式是结合二者的优势，将大模型的世界知识输入到推荐系统中去，提升推荐系统的效果上限。

对比曾经红极一时的基于知识图谱的RippleNet，KGAT等GNN方案，大模型其实是在一张包含了世界知识的知识图谱上训练的，而其生成的对于每个知识节点的Embedding显然具备更丰富的相似性关系。所以从知识输入的角度来说，大模型对知识图谱GNN方案有着降维打击似的优势。而相比个性化的构造一些内容型/知识型特征输入推荐模型这种小打小闹的方案，大模型也显然具有更强的通用性，所以我们几乎可以得出结论：


大模型相比传统的知识图谱、人工构造内容型特征等知识输入方式，无论是在知识总量，还是知识Embedding的质量上，都具备明显的优势。今后在考虑构造知识型/内容型特征时，大模型几乎可以说是最优的解决方案。

> 怎么做

第一种是LLM生成Embedding后输入推荐系统。对于LLaMA这样的开源大模型来说，我们可以知道模型所有的参数，也可以对模型进行改造，所以在预训练完成之后，大模型可以被当作一个多模态特征的编码器，把多模态特征转换成同一隐空间内的Embedding，这样就可以与深度学习推荐系统无缝衔接。


第二种是LLM生成文字Token后输入推荐系统。对于ChatGPT这样的闭源大模型来说，我们无法让模型直接生成Embedding，而只能通过它的API生成Prompt对应的token序列。这时token序列就可以成为大模型向推荐系统传播知识的媒介。当然在推荐模型中token还是会被转换成embedding来参与特征交叉。

本质上，多模态大模型这里被当做了一个功能强大的encoder，过去我们想构造一个多模态推荐系统，还需要为相应的模态分别构建encoder，现在一个预训练的多模态大模型，或者是成熟大模型公司的api就解决所有问题。具体的方案有很多，比如下图的MoRec使用Switch游戏的介绍图片和介绍文字构建多模态特征，进行游戏推荐。

比如快手的多模态推荐模型方案EM3（End-to-end training of Multimodal Model and ranking Model）。可以看到其最大的特点是用多模态大模型抽取出用户行为历史物品和目标商品的内容特征，Embedding化后供后续模型做特征交叉。值得注意的是，ID型特征还保留在模型中，因为ID特征和多模态内容型特征是互补的关系，二者包含的信息是不可相互替代的。

总的来说，不管这些方案的结构是怎样的，训练方式是预训练还是E2E训练，我们只要记住一件事情就可以理解他们的核心思路，那就是他们无一例外都在利用多模态大模型的能力把多模态的信息转换成模型可以学习吸收的Embedding或者文字token。也无论相关的学术词汇多复杂，比如知识增强，大模型知识图谱，大模型特征工程等等，都可以归为这一类，那就是利用大模型改变推荐系统学习知识的方式。

## 二、大模型改变了“智能体”本身的结构

当今的大模型结构一般是基于transformer结构的生成式模型结构。大模型的结构和传统的深度学习推荐模型区别甚大。本质上，推荐模型是一个分类模型或排序模型，而大模型是生成式模型。在深度学习推荐模型2021年之后遇到效果提升的瓶颈之时，大模型的生成式模型结构是不是推荐模型的新答案，新范式？在大模型改造了智能体的结构之时，它能否也颠覆推荐模型，带来新的增长极，这是所有人期望去探索的。

> LLM对推荐模型本身的改造

大模型改造推荐系统的第二个层级是对推荐系统本身推荐方式的改造，或者更具代表性的是对推荐模型本身的改造。这一大趋势携带着所有推荐系统工程师们的一个深切的希望——深度学习的红利逐渐枯竭之后，推荐模型新的发展范式到底在哪里？



对于这一新范式的追寻，其实也经历了三个小的发展阶段。第一个阶段是探索期，甚至带着点为了在推荐系统中应用大模型而应用大模型的追热点时期。这一阶段的典型产物是一堆有玩具性质的prompt推荐系统。比如亚马逊的研究人员给出的一个解决方案，PALR（Personalization Aware LLMs for Recommendation，个性化感知大语言推荐系统）。它的主要推荐流程是把用户的历史行为，和候选物品的相关信息统统通过prompt的方式输入给大模型，让大模型自己来进行个性化推荐

它的一般流程是，大模型先利用用户的历史行为推断出用户的基本兴趣画像。然后，再把用户的画像、历史行为文字描述、候选物品信息输入大模型，给出最终的推荐列表，

这一过程虽然能够得出一个靠谱的推荐结果，但如果你是一个有些行业经验的从业者，一定能看出，这一方案在扩展性，模型的工程指标和信息利用程度上，都不可能好于现在的深度学习推荐模型。所以我称之为探索期的玩具推荐模型。即使有后续的其他类似推荐系统的探索，比如华为的UniLLMRec等，仍是一类较难工业化的推荐系统方案。


于是，大模型推荐系统的探索来到了第二阶段，到底如何在工业级推荐系统中让大模型产生业务指标的真正提升。Meta的生成式推荐模型GR（Generative Recommendation）方案率先给我们曙光。GR的线上核心业务指标大幅提升了12.4%，这毫无疑问给整个推荐模型领域注入了一个强心针。


技术方案上，GR也可谓是完全脱胎于大模型的结构，直接推翻了传统推荐模型CTR预估式的point wise模型结构，而是采用生成式语言模型的结构，从预测点击率的问题，变成预测用户下一个行为是什么这种生成式推荐的问题。针对这种新的问题提出方式，模型的结构也完全遵循LLM的序列模型结构，输入的特征也全部通用化为序列特征的形式。毫无疑问，这是革命性的。


GR的工程优化方式也是非常巧妙，比如模型一次inference即可生成对所有候选物品的预估结果，模型的transformer结构进行了高效的简化等等，可以看出Meta的工程师们是在竭尽所有智慧和技巧推GR上线。

Meta GR的珠玉在前，利用LLM结构优化推荐系统的各个模块似乎一下子成为了新的流行趋势，并有不少公司拿到了切实的业务效果。召回层、粗排层、精排层的模型方案都有了大模型的影子。这第三阶段大有百花齐放的趋势。这里举一个比较有代表性的例子是快手的基于Transformer的召回模型KuaiFormer。

和Meta GR一样，KuaiFormer也把过去“视推荐为分类问题”的做法改成了“把推荐视为预测用户的next token”的问题，于是就可以利用Transfomer的结构预测用户的next interest embedding，再把这些embedding当作ANN召回的索引Embedding，就实现了LLM思想对召回层的改造。可以说，这类方案的核心是用训练LLM的思路解决推荐问题，用Transformer为基础的模型结构。

该类思路的核心——用生成式模型的思路作为解决推荐问题的新范式，就可以把这类思路应用在推荐系统各类模型的改造之上。




## 三、大模型开始创造一个”新世界“



OpenAI在发布Sora之时，喊出了“Sora是这个世界的模拟器”的口号。大模型最大的野心其实是完全创造一个新的虚拟世界。回到推荐系统领域，其实推荐系统一直以来的使命是帮助人发掘感兴趣的信息和内容。但大模型极强的内容生成能力，让“个性化内容生成”成为可能。也就是说，大模型有可能越过“推荐”这个环节，直接为用户创造个性化内容，这才是大模型可能带给推荐系统最大的革命。

> 大模型在推荐内容生成上的应用

相比推荐系统技术上的改造，这波AI革命对推荐领域最大的影响，我想一定是"推荐内容的个性化生成"。如果说OpenAI Sora的口号“成为世界的模拟器”还有点好高骛远的话，那AIGC生成推荐内容的很多想法已经产品化，越来越深刻地影响着现在的推荐方式。



宏观上来说，新的推荐内容生成方式是把AI生成器（图来自生成式推荐系统的框架GeneRec），或者叫AI创作者纳入到推荐系统中来。

AI生成器参与创作的方式有两种：



1.辅助人类创作者创作，比如根据人类的Prompt生成文字、图片或视频。

2.直接根据用户反馈生成个性化的推荐内容。



AI创作者创作的内容出路就一个，那就是与人类创作者创作的内容一样流入候选物品集，一同参与推荐过程。



无论是AI辅助内容创作和AI个性化内容生成，它的基础都离不开扩散模型（diffusion model）。无论是大名鼎鼎的Stable Diffusion，还是轰动一时的Sora，其底层的prompt Embedding到图片的关键步骤，都是基于扩散模型的。

再比如数字人技术，可以把文字输入自动转换成口播视频，产品介绍，甚至新闻播报节目。这是内容创作生产力的大幅解放。

再比如，目前已经有一些模版化，规则化的AI生成视频，在短视频平台上取得了非常不错的点击量。我想下面一些AI生成的视频你一定刷到过。


